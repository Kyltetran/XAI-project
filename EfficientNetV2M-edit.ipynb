{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2M\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.applications.efficientnet_v2 import preprocess_input as base_preprocess\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c3ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "IMAGE_ROOT_DIR = \"./skincancer-dataset/HAM10000_images\"\n",
    "METADATA_PATH = \"./skincancer-dataset/HAM10000_metadata\"\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "SAVE_DIR = './saved_models_skincancer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD & PREPROCESS METADATA ===\n",
    "df = pd.read_csv(METADATA_PATH)\n",
    "le = LabelEncoder()\n",
    "df['label_idx'] = le.fit_transform(df['dx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be069ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map image_id to full image path (search recursively)\n",
    "all_image_paths = glob(os.path.join(IMAGE_ROOT_DIR, '**', '*.jpg'), recursive=True)\n",
    "image_map = {os.path.splitext(os.path.basename(p))[0]: p for p in all_image_paths}\n",
    "df['image_path'] = df['image_id'].map(image_map)\n",
    "df = df.dropna(subset=['image_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22118e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "image_paths = df['image_path'].values\n",
    "label_indices = df['label_idx'].values\n",
    "num_classes = len(le.classes_)\n",
    "\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "    image_paths, label_indices, test_size=0.1, stratify=label_indices, random_state=42)\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    train_paths, train_labels, test_size=0.1, stratify=train_labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TF DATA PIPELINE WITH AUGMENTATION ===\n",
    "def decode_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "\n",
    "def augment(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    return image, label\n",
    "\n",
    "def build_dataset(paths, labels, training=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    ds = ds.map(decode_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.shuffle(1000)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_data = build_dataset(train_paths, train_labels, training=True)\n",
    "val_data = build_dataset(val_paths, val_labels, training=False)\n",
    "test_data = build_dataset(test_paths, test_labels, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b3880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MODEL SETUP ===\n",
    "base_model = EfficientNetV2M(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845fb37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CALLBACKS ===\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "checkpoint_path = os.path.join(SAVE_DIR, 'EfficientNetV2M.h5')\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_accuracy', verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, mode='max', min_lr=1e-4, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74b82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAIN ===\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623ae288",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('./saved_models_skincancer/EfficientNetV2M.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d918168",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test Loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d797dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Convert predictions and true labels to integer format\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "true_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "# Calculate the classification report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5573be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(true_labels, np.round(predicted_labels))\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b854766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "cm_plot_labels = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
    "\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bada49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names\n",
    "class_names = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Get the number of classes\n",
    "num_classes = test_labels.shape[1]\n",
    "\n",
    "# Initialize a figure to plot ROC curves\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Loop through each class\n",
    "for class_index in range(num_classes):\n",
    "    # Compute ROC curve and ROC AUC for the current class\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels[:, class_index], predictions[:, class_index])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Plot ROC curve for the current class\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{class_names[class_index]} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot the diagonal line (random chance)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)\n",
    "\n",
    "# Set plot properties\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) - Multiclass')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-keras-vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d042d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from tensorflow.python.client import device_lib\n",
    "device_list = device_lib.list_local_devices()\n",
    "gpus = [device.name for device in device_list if device.device_type == 'GPU']\n",
    "print('TensorFlow recognized {} GPUs'.format(len(gpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad415509",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_titles = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\n",
    "num_images = len(image_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_int = np.argmax(test_labels, axis=1)\n",
    "# Find the indices of the first image from each class\n",
    "class_indices = [np.where(test_labels_int == i)[0][0] for i in range(len(image_titles))]\n",
    "\n",
    "# Create an array to store the images\n",
    "image_array = []\n",
    "\n",
    "# Create a single row of plots\n",
    "num_images = len(image_titles)\n",
    "fig, ax = plt.subplots(1, num_images, figsize=(15, 3))\n",
    "\n",
    "for i, title in enumerate(image_titles):\n",
    "    ax[i].set_title(title, fontsize=12)\n",
    "    ax[i].axis('off')\n",
    "\n",
    "    # Display the image from test data\n",
    "    img = test_data[class_indices[i]]\n",
    "    image_array.append(img)  # Store the image in the array\n",
    "\n",
    "    ax[i].imshow(img)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "X = base_preprocess(np.array(image_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce135a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_titles = ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\n",
    "num_images = len(image_titles)\n",
    "\n",
    "# Convert one-hot encoded labels to integer labels\n",
    "test_labels_int = np.argmax(test_labels, axis=1)\n",
    "# Create an array to store the images\n",
    "image_array = []\n",
    "\n",
    "# Create subplots with 2 rows\n",
    "num_rows = 2\n",
    "num_cols = (num_images + 1) // num_rows\n",
    "fig, ax = plt.subplots(num_rows, num_cols, figsize=(5, 3))\n",
    "\n",
    "for i, title in enumerate(image_titles):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    ax[row, col].set_title(title, fontsize=8)\n",
    "\n",
    "    # Find indices of images for the current class\n",
    "    class_indices = np.where(test_labels_int == i)[0]\n",
    "    random_index = np.random.choice(class_indices)  # Choose a random index\n",
    "\n",
    "    # Display the image from test data\n",
    "    img = test_data[random_index]\n",
    "    image_array.append(img)  # Store the image in the array\n",
    "\n",
    "    ax[row, col].imshow(img)\n",
    "    ax[row, col].axis('off')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for i in range(len(image_titles), num_rows * num_cols):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    fig.delaxes(ax[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "X = base_preprocess(np.array(image_array))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27703b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "\n",
    "replace2linear = ReplaceToLinear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d75f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras_vis.utils.scores import CategoricalScore\n",
    "\n",
    "score = CategoricalScore([0, 1, 2, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6807b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from matplotlib import cm\n",
    "from tf_keras_vis.scorecam import Scorecam\n",
    "\n",
    "# Create ScoreCAM object\n",
    "scorecam = Scorecam(model, model_modifier=replace2linear)\n",
    "\n",
    "# Generate heatmap with Faster-ScoreCAM\n",
    "cam = scorecam(score,\n",
    "               X,\n",
    "               penultimate_layer=-1,\n",
    "               max_N=10)\n",
    "\n",
    "## Since v0.6.0, calling `normalize()` is NOT necessary.\n",
    "# cam = normalize(cam)\n",
    "\n",
    "# Calculate the number of rows and columns for subplots\n",
    "num_rows = 2\n",
    "num_cols = (num_images + 1) // num_rows\n",
    "\n",
    "# Render\n",
    "f, ax = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(5, 3))\n",
    "\n",
    "for i, title in enumerate(image_titles):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "\n",
    "    heatmap = np.uint8(cm.jet(cam[i])[..., :3] * 255)\n",
    "    ax[row, col].set_title(title, fontsize=8)\n",
    "    ax[row, col].imshow(image_array[i])\n",
    "    ax[row, col].imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "    ax[row, col].axis('off')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for i in range(len(image_titles), num_rows * num_cols):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    f.delaxes(ax[row, col])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from matplotlib import pyplot as plt, cm\n",
    "from tf_keras_vis.scorecam import Scorecam\n",
    "\n",
    "# Assuming you have already defined model and replace2linear\n",
    "\n",
    "# Create ScoreCAM object\n",
    "scorecam = Scorecam(model, model_modifier=replace2linear)\n",
    "\n",
    "# Generate heatmaps with Faster-ScoreCAM\n",
    "cam = scorecam(score, X, penultimate_layer=-1, max_N=10)\n",
    "\n",
    "# Calculate the number of images\n",
    "num_images = len(image_titles)\n",
    "\n",
    "# Create a single row plot\n",
    "fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "\n",
    "for i, title in enumerate(image_titles):\n",
    "    heatmap = np.uint8(cm.jet(cam[i])[..., :3] * 255)\n",
    "\n",
    "    combined_image = cv2.addWeighted(image_array[i], 0.5, heatmap, 0.5, 0)\n",
    "\n",
    "    axes[i].set_title(title, fontsize=8)\n",
    "    axes[i].imshow(combined_image)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064e2a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from matplotlib import pyplot as plt, cm\n",
    "from tf_keras_vis.scorecam import Scorecam\n",
    "\n",
    "# Assuming you have already defined model and replace2linear\n",
    "\n",
    "# Create ScoreCAM object\n",
    "scorecam = Scorecam(model, model_modifier=replace2linear)\n",
    "\n",
    "# Generate heatmaps with Faster-ScoreCAM\n",
    "cam = scorecam(score, X, penultimate_layer=-1, max_N=10)\n",
    "\n",
    "# Calculate the number of images\n",
    "num_images = len(image_titles)\n",
    "\n",
    "# Create a single row plot\n",
    "fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "\n",
    "for i, title in enumerate(image_titles):\n",
    "    heatmap = np.uint8(cm.jet(cam[i])[..., :3] * 255)\n",
    "\n",
    "    combined_image = cv2.addWeighted(image_array[i], 0.5, heatmap, 0.5, 0)\n",
    "\n",
    "    axes[i].set_title(title, fontsize=8)\n",
    "    axes[i].imshow(combined_image)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf219-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
